# BrainFound ğŸ§ âœ¨

BrainFound is a 3D self-supervised foundation model for brain MRI, designed to tackle the growing demand for accurate, scalable, and automated neuroimaging analysis. By extending the DINOv2 framework from 2D to volumetric, multimodal brain scans, BrainFound learns rich representations from unlabeled data and powers both disease classification and anatomical segmentation in a unified framework.

# Why BrainFound?

- Radiologist workloads are unsustainable â€“ interpreting one image every 3â€“4 seconds leads to delays and errors.

- Labeled datasets are expensive â€“ traditional supervised deep learning struggles with scalability.

- 3D context matters â€“ volumetric MRI preserves spatial relationships critical for accurate diagnosis.

- Multimodal imaging improves performance â€“ combining T1, T2, and FLAIR captures complementary structural information.

BrainFound addresses these challenges with self-supervised learning, enabling generalizable, annotation-efficient brain MRI analysis.

# Key Features ğŸš€

- 3D SSL model â€“ learns from volumetric brain MRI scans.

- Multimodal support â€“ T1, T2, FLAIR (easily extendable to other contrasts).

- Voxel resolution agnostic â€“ works with isotropic and anisotropic scans.

- Unified multitask capability â€“ supports:

    - Multi-disease classification (e.g., dementia subtypes, tumor grading)

   -  Multi-region anatomical and tumor segmentation

- Robust generalization â€“ works across datasets, resolutions, and imaging protocols.

- Few-shot performance â€“ excels with limited labeled data.


![BrainFound Workflow](docs/brainfound_workflow.png)



# Repository Structure

BrainFound/

â”œâ”€â”€ Dataset/

â”‚   â”œâ”€â”€ __init__.py

â”‚   â””â”€â”€ multimodal_mri_dataset.py

â”œâ”€â”€ Preprocessing/

â”‚   â”œâ”€â”€ dicom_to_nifti.py

â”‚   â””â”€â”€ kfold_split.py

â”œâ”€â”€ docs/

â”‚   â””â”€â”€ brainfound_workflow.png

â”œâ”€â”€ examples/

â”‚   â”œâ”€â”€ demo.py

â”‚   â”œâ”€â”€ run_dataloader_example.py

â”‚   â””â”€â”€ use_preprocess_with_mripreprocessor

â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ dinov2_base.py

â”‚   â””â”€â”€ brainfound.py

â”œâ”€â”€ scripts/

â”‚   â”œâ”€â”€ generate_folds.py

â”‚   â””â”€â”€ preprocess_with_mripreprocessor.py

â”œâ”€â”€ LICENSE

â”œâ”€â”€ README.md

â””â”€â”€ requirements.txt



# Requirements & Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/Moona-Mazher/BrainFound.git
cd BrainFound

2ï¸âƒ£ Create a Python environment (recommended)

Using conda:

conda create -n brainfound python=3.11
conda activate brainfound


Or using virtualenv:

python -m venv brainfound_env
brainfound_env\Scripts\activate   # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt


Key packages included: torch, torchvision, albumentations, SimpleITK, pandas, numpy, mripreprocessor, scikit-learn, matplotlib.

4ï¸âƒ£ Verify installation
python -c "import torch, albumentations, SimpleITK, pandas, numpy; print('Packages loaded!')"

# Citation

If you use BrainFound in your work, please cite:

@article{mazher2025towards,

  title={Towards Generalisable Foundation Models for 3D Brain MRI},
  
  author={Mazher, Moona and Parker, Geoff JM and Alexander, Daniel C},
  
  journal={arXiv preprint arXiv:2510.23415},
  
  year={2025}
  
}
